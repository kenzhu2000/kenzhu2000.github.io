%----PrefaceImport----%
\documentclass{article}
\usepackage{fancyhdr}
\usepackage[a4paper,margin=1in,headsep=25pt]{geometry}
\usepackage{lipsum,hyperref}
\usepackage{enumerate,fullpage,proof}
\usepackage[fontsize=12pt]{fontsize}
\usepackage{amsmath,amscd,amsbsy,amssymb,latexsym,url,bm,amsthm}
\usepackage{epsfig,graphicx,subfigure}
\usepackage{listings}
\usepackage[usenames]{xcolor}
\usepackage{tcolorbox}

\newtheorem{thm}{Theorem}
\newtheorem{lemma}[thm]{Lemma}

\pagestyle{fancy}
\pagenumbering{Alph}
\setlength{\headheight}{36.0pt}
\headsep = 25pt
\fancyhf{}
\lhead{CSE 4392 Special Topic: Natural Language Processing}
\rhead{Homework 5: Word Embeddings}
\lfoot{2025 Kenny Zhu & Essam Abdelghany}
\rfoot{Plagiarism will not be tolerated. We are here to help.}


% New command for blank spaces after questions
\newcommand{\answerbox}{
    \vspace{7cm} % Adjust the space size as needed
}
\newcommand{\answerboxbig}{
    \vspace{20cm} % Adjust the space size as needed
}
\newcommand{\answerboxsmall}{
    \vspace{3cm} % Adjust the space size as needed
}


%----Documentation----%
\begin{document}

\title{CSE 4392 Special Topic: Natural Language Processing}
\author{Homework 6 - Spring 2025}
\date{Due Date: Mar 3, 2025, 11:59 p.m. Central Time}
\maketitle
\thispagestyle{fancy}

%----Homeworks----%

\section*{Problem 1 - 50\%}

For this task, you are provided with a very simple dataset consisting of labeled sequences of words, 
where each word is associated with a specific part-of-speech (POS) tag. 

\begin{itemize}
    \item Training Data:
    \begin{itemize}
        \item "cats (NN) jump (VB) high (JJ)" (Noun-Verb-Adjective)  
        \item "apples (NN) grow (VB) red (JJ)" (Noun-Verb-Adjective)  
        \item "cats (NN) run (VB) quickly (RB)" (Noun-Verb-Adverb)  
        \item "red (JJ) dogs (NN) quickly (RB) grow (VB)" (Adjective-Noun-Adverb-Verb)  
    \end{itemize}
    
    \item Test Data:
    \begin{itemize}
        \item "cats (NN) quickly (RB) jump (VB)" (Noun-Adverb-Verb)  
        \item "dogs (NN) grow (VB) high (JJ)" (Noun-Verb-Adjective)  
    \end{itemize}
\end{itemize}

\answerboxbig


\subsection*{Compute Training Parameters - 30\%}
Train the HMM by computing the training parameters (transition matrix, emission matrix and prior probabilities vector). Show steps by at least writing for each value the original fraction representing counts a/b.
\answerboxbig

\subsection*{Viterbi Decoding - 20\%}
For each test example, use Viterbi decoding to find the most probable sequence of tags. Compute the word-level and sequence-level accuracies.
\answerboxbig

%And then use the Viterbi algorithm to calculate the most likely sequence 
%of POS tags for the test data.
\section*{Problem 2 - 40\%}
Implement the Hidden Markov Model in object-oriented Python. You class must have a fit method, infer method and evaluate method that you should test on the dataset shown above and match your handwritten results. Your implementation of the infer method should include the Viterbi algorithm and you should implement a bruteforce inference method for testing purposes to ensure the Viterbi algorithm is working correctly.
\\
\\
Preferably, submit a PDF notebook using \hyperlink{https://htmtopdf.herokuapp.com/ipynbviewer/#google_vignette}{this tool}. Or submit a Python file and screenshot for the output. If your code output does not match the reported output, zero will be granted.

\section*{Problem 2 - 10\%}
Compare HMM and CRFs and highlight scenarios where you may use on over the other.
\end{document}
