%----PrefaceImport----%
\documentclass{article}
\usepackage{fancyhdr}
\usepackage[a4paper,margin=1in,headsep=25pt]{geometry}
\usepackage{lipsum,hyperref}
\usepackage{enumerate,fullpage,proof}
\usepackage[fontsize=12pt]{fontsize}
\usepackage{amsmath,amscd,amsbsy,amssymb,latexsym,url,bm,amsthm}
\usepackage{epsfig,graphicx,subfigure}
\usepackage{listings}
\usepackage[usenames]{xcolor}
\usepackage{tcolorbox}
\usepackage{minted}

\newtheorem{thm}{Theorem}
\newtheorem{lemma}[thm]{Lemma}

\pagestyle{fancy}
\pagenumbering{Alph}
\setlength{\headheight}{36.0pt}
\headsep = 25pt
\fancyhf{}
\lhead{CSE 4392 Special Topic: Natural Language Processing}
\rhead{Homework 9: RNNs}
\lfoot{2025 Kenny Zhu & Essam Abdelghany}
\rfoot{Plagiarism will not be tolerated. We are here to help.}


% New command for blank spaces after questions
\newcommand{\answerbox}{
    \vspace{7cm} % Adjust the space size as needed
}
\newcommand{\answerboxbig}{
    \vspace{20cm} % Adjust the space size as needed
}
\newcommand{\answerboxsmall}{
    \vspace{3cm} % Adjust the space size as needed
}


%----Documentation----%
\begin{document}

\title{CSE 4392 Special Topic: Natural Language Processing}
\author{Homework 9 - Spring 2025}
\maketitle
\thispagestyle{fancy}


\subsection*{Question 1 - 40\%}
Provide a step-by-step proof of the following formula for RNNs. Any omissions or gaps in the reasoning may result in mark deductions.
$$\frac{\partial L }{\partial \mathbf{W}} = -\frac{1}{n}\sum_{t=1}^{n}\sum_{k=1}^{t}  \frac{\partial L_t }{\partial  \mathbf{h}_t}\left ( \prod_{j=k+1}^{t}  \frac{\partial \mathbf{h}_j  }{\partial  \mathbf{h}_{j-1}} \right ) \frac{\partial \mathbf{h}_k }{\partial \mathbf{W}},$$
Then discuss intuitively how you expect the formula to change for bidirectional RNNs. 
\answerboxbig

\subsection*{Question 2 - 60\%}
Compare LSTMs, GRUs and RNNs with PyTorch for fake news detection by employing the following \href{https://www.kaggle.com/c/fake-news/data}{Fake News Dataset}. Implement the whole NLP pipeline as we did before for spam classification with RNNs and submit a notebook or report with your results. 
\\
\\
You may penalized if your results (in terms of F1 score) significantly underperform compared to the ordinary so you may need to do some hyperparametertuning. Let the validation set be 20\% of the provided training set and include at least two visuals (one for the data and another for training and validation losses). At least one table comparins the three architectures should be presented.
\\
\\
Preferably, submit a PDF notebook using \hyperlink{https://htmtopdf.herokuapp.com/ipynbviewer/#google_vignette}{this tool}. Or submit a Python file and a report documenting your work.

\end{document}
