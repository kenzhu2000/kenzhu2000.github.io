%----PrefaceImport----%
\documentclass{article}
\usepackage{fancyhdr}
\usepackage[a4paper,margin=1in,headsep=25pt]{geometry}
\usepackage{lipsum,hyperref}
\usepackage{enumerate,fullpage,proof}
\usepackage[fontsize=12pt]{fontsize}
\usepackage{amsmath,amscd,amsbsy,amssymb,latexsym,url,bm,amsthm}
\usepackage{epsfig,graphicx,subfigure}
\usepackage{listings}
\usepackage[usenames]{xcolor}
\usepackage{tcolorbox}
\usepackage{minted}

\newtheorem{thm}{Theorem}
\newtheorem{lemma}[thm]{Lemma}

\pagestyle{fancy}
\pagenumbering{Alph}
\setlength{\headheight}{36.0pt}
\headsep = 25pt
\fancyhf{}
\lhead{CSE 4392 Special Topic: Natural Language Processing}
\rhead{Homework 8: EM}
\lfoot{2025 Kenny Zhu & Essam Abdelghany}
\rfoot{Plagiarism will not be tolerated. We are here to help.}


% New command for blank spaces after questions
\newcommand{\answerbox}{
    \vspace{7cm} % Adjust the space size as needed
}
\newcommand{\answerboxbig}{
    \vspace{20cm} % Adjust the space size as needed
}
\newcommand{\answerboxsmall}{
    \vspace{3cm} % Adjust the space size as needed
}


%----Documentation----%
\begin{document}

\title{CSE 4392 Special Topic: Natural Language Processing}
\author{Homework 8 - Spring 2025}
\maketitle
\thispagestyle{fancy}

%----Homeworks----%
\section*{Problem 1 - 30\%}

Show that your HMM code from the last assignment is a maximum likelihood estimate by computing the likelihood of the training set over a large set of randomly selected parameter matrices and comparing its value with that obtained using the trained HMM parameters.

\section*{Problem 2 - 70\%}
We have two biased coins:
\begin{itemize}
    \item Coin A has a probability \( p \) of landing heads.
    \item Coin B has a probability \( q \) of landing heads.
\end{itemize}
In each experiment:
\begin{itemize}
    \item A coin is randomly selected based on a mixing parameter \( \lambda \):
    \begin{itemize}
        \item With probability \( \lambda \), Coin A is selected.
        \item With probability \( 1 - \lambda \), Coin B is selected.
    \end{itemize}
    \item The selected coin is tossed \( m \) times, and the number of heads is recorded.
\end{itemize}
The goal is to use the Expectation-Maximization (EM) algorithm to estimate the true parameters \( \lambda, p, q \) from the observed data (number of heads per experiment).

\subsection*{Starter Code}
\begin{minted}{python}
import numpy as np

# ------------------------
# Simulation settings:
# ------------------------
np.random.seed(42)

# True parameters
true_lambda, true_p, true_q = 0.6, 0.7, 0.4
m, N = 10, 500  # m = tosses per experiment, N = number of experiments

# Simulate complete data
coin_choices = np.random.rand(N) < true_lambda
data = np.random.binomial(m, np.where(coin_choices, true_p, true_q))

# Complete assignments (1 for coin A, 0 for coin B)
assignments = coin_choices.astype(int)

# ------------------------
# EM algorithm initialization:
# ------------------------
lambda_est, p_est, q_est = 0.5, 0.6, 0.5
max_iters, tol = 200, 1e-6

# TODO: Implement the EM algorithm
# Ensure it converges to the right answer for at least one initialization 
# and make a table of at least 10 rows detailing the number of iterations 
# required for each of different initializations.
\end{minted}
\\
\\
Preferably, submit a PDF notebook using \hyperlink{https://htmtopdf.herokuapp.com/ipynbviewer/#google_vignette}{this tool}. Or submit a Python file and screenshot for the output. If your code output does not match the reported output, zero will be granted.

\end{document}
