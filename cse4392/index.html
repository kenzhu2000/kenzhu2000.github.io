<html>
<head>
<title>CSE 4392 Special Topics (Natural Language Processing)</title>
</head>
<body>
<h1> CSE 4392 Special Topics (Natural Language Processing)</h1>

<h2>Course Summary</h2>
Natural language processing (NLP) is the ability of a computer program to understand and further generate (mostly) human language as it is spoken and written -- referred to as natural language. It is a key component of artificial intelligence (AI), and is considered a grand challenge in AI. NLP has existed for more than 50 years and has roots in the field of linguistics. This course introduces the both classical and contempory concepts in NLP especially from a statistical and machine learning approach. It aims to provide the students with a basic understanding and appreciation of key NLP theories such as lexicons, grammar, parsing and language modeling, as well as emerging NLP applications including text classification, information retrieval, machine translation, text summarization, question answering and dialogue systems. Students will practice the knowledge acquired in this course through a team project which aims at solving one particular NLP problem of their choice.
<hr>
<font color=orange>
<h2>Latest News and Announcements</h2>
<ul>
<li>Jan 13, 2025: The new course website starts! The syllabus of the course is available on Canvas and <a href="cse4392-2025-syllabus.docx">here</a>!
<li>Jan 27, 2025: Assignment 2 was released.
<li>Feb 6, 2025: Assignment 3 was released.
<li>Feb 15, 2025: Assignment 4 was released.
<li>Feb 19, 2025: Assignment 5 was released.
<li>Feb 23, 2025: On Monday, Mar 3, we will hold a special session in which every project group will give a 10-15 min presentation to talk about the basic idea behind your mini research project. Please make sure your presentation include the following elements: members of the project group, background and motivation, problem/task definition, proposed approaches, proposed evaluation method, expected outcome from the evaluation, potential applications of your research. Essam and I will listen to your presentation and provide our comments and suggestions after each presentation. Please then calibrate your proposal if necessary and start working on the project. Please make sure you have formed the project groups (up to 2 persons) before this session.
<li>Feb 26, 2025: Assignment 6 was released.
</ul>
</font>
<hr>

<h2>Administrative Information</h2>
<p><b>Lectures</b>: Mon/Wed 2:30-3:50 PM, WH-311.

<p><b>Instructor</b>: <a href="https://kenzhu2000.github.io/">Kenny Zhu</a> 
- ERB-535 Phone: 3420-4592  Email: kenny[dot]zhu@uta[dot]edu<br>
Office hours: By appointment
<br>

<p><b>Teaching Assistant</b>:
Essam Abdelghany<br>
Email: exa0039[at]mavs[dot]uta[dot]edu<br>
Office hours: Thu 9-11 AM @ ERB-316

<p><b>Reference Textbooks</b>: 
<ol>
<li><a href="slp-ed3.pdf">Speech and Language Processing (3rd ed)</a> by Dan Jurafsky and James Martin, The Prentice Hall.
<li><a href="fsnlp-ed2.pdf">Foundations of Statistical Natural Language Processing</a> by Chritopher Manning and Hinrich Schutze, The MIT Press.<br>
<li><a href="ir-ed1.pdf">Introduction to Information Retrieval</a> by Christopher D. Manning, Prabhakar Raghavan, Hinrich Sch√ºtze, The Cambridge University Press.<br>
</ol>

<p><b>Assessment</b>: <br>
<ol>
<li>In-class quizzes: 10%
<li>Tutorial participation: 5% bonus
<li>Assignments: 30%  
<li>Project: 30% <a href="project.html">Project Website</a>
<li>Final Exam: 30%
</ol>

<h2>Schedule</h2>
<table width="100%" border="1">
<tr><td><b>Week</b></td><td><b>Date</b></td><td><b>Topic</b></td>
<td><b>Slides</b></td><td><b>Resources</b></td><td><b>Homework</b></td>
</tr>
<tr>
<td>1</td><td>01/13/2025</td>
<td>Introduction</td><td><a href="L1-intro.pdf">[lecture] 
<a href="t1.zip">[tutorial]</a>
</td>
<td>MS Ch 3, JM Ch 17</td><td>
<a href="hw1.pdf">hw1 (pdf)</a>
<a href="hw1.tex">hw1 (tex)</a>
</td>
</tr>
<tr>
<td>2</td><td>01/29/2025</td>
<td>Language Models</td><td><a href="L2-langmodel.pdf">[lecture] 
<a href="t2.zip">[tutorial]</a>
</td>
<td>JM Ch 3</td><td>
<a href="hw2.pdf">hw2 (pdf)</a>
<a href="hw2.tex">hw2 (tex)</a>
</td>
</tr>
<tr>
<td>3</td><td>02/06/2025</td>
<td>Text Classification</td><td><a href="L3-tc.pdf">[lecture] 
<a href="t3.zip">[tutorial]</a>
</td>
<td>JM Ch 4</td><td>
<a href="hw3.pdf">hw3 (pdf)</a>
<a href="hw3.tex">hw3 (tex)</a>
</td>
</tr>
<tr>
<td>4</td><td>02/12/2025</td>
<td>Loglinear Models</td><td><a href="L4-loglinear.pdf">[lecture] 
<a href="t4.pptx">[tutorial]</a>
</td>
<td>JM Ch 5</td><td>
<a href="hw4.zip">hw4 (zip)</a>
<a href="hw4.tex">hw4 (tex)</a>
</td>
</tr>
<tr>
<td>5</td><td>02/19/2025</td>
<td>Word Embeddings</td><td><a href="L5-word.pdf">[lecture] 
<a href="t5.zip">[tutorial]</a>
</td>
<td>JM Ch 6, papers in slides</td><td>
<a href="hw5.pdf">hw5 (pdf)</a>
<a href="hw5.tex">hw5 (tex)</a>
</td>
</tr>
<<<<<<< HEAD
<tr>
<td>6</td><td>02/24/2025</td>
<td>Neural Network Basics</td><td><a href="L6-nn.pdf">[lecture] 
<a href="t6.pptx">[tutorial]</a>
</td>
<td>JM Ch 7</td><td>
<a href="hw6.pdf">hw6 (pdf)</a>
<a href="hw6nn.png">hw6 (figure png)</a>
<a href="hw6.tex">hw6 (tex)</a>
</td>
</tr>
=======
<tr>
<td>6</td><td>02/24/2025</td>
<td>Neural Network Basics</td><td><a href="L6-nn.pdf">[lecture] 
<a href="t6.zip">[tutorial]</a>
</td>
<td>JM Ch 7</td><td>
<a href="hw6.pdf">hw6 (pdf)</a>
<a href="hw6.tex">hw6 (tex)</a>
</td>
</tr>
<!--
<tr>
<td>5</td><td>02/17/2025</td>
<td>Research Proposal</td><td>N/A
</td>
<td>N/A</td><td>
N/A
</td>
</tr>


>>>>>>> b5e8b858ed2ed95614651fcb694193ce718bbaa9
<tr>
<td>7</td><td>03/04/2025</td>
<td>Research Proposal</td><td>N/A
</td>
<td>N/A</td><td>
N/A
</td>
</tr>

<tr>
<td>8</td><td>03/17/2025</td>
<td>Sequence Models</td><td><a href="L7-seq.pdf">[lecture] 
<a href="t7.pptx">[tutorial]</a>
</td>
<td>JM Ch 8</td><td>
<a href="hw7.pdf">hw7 (pdf)</a>
<a href="hw7.tex">hw7 (tex)</a>
</td>
</tr>
<!--
<tr>
<td>9</td><td>03/25/2025</td>
<td>Expectation Maximization</td><td><a href="L8-em.pdf">[lecture] 
<a href="t8.pptx">[tutorial]</a>
</td>
<td><a href="EM_Collins97.pdf">Notes by Michael Collins</a></td><td>
<a href="hw8.pdf">hw8 (pdf)</a>
<a href="hw8.tex">hw8 (tex)</a>
</td>
</tr>
<tr>
<td>10</td><td>04/01/2025</td>
<td>Recurrent Neural Networks</td><td><a href="L9-rnn.pdf">[lecture] 
<a href="t9.pptx">[tutorial]</a>
</td>
<td>JM Ch 9, 
<a href="https://colah.github.io/posts/2015-08-Understanding-LSTMs/">Understanding LSTM</a>
</td>
<td>
<a href="hw9.pdf">hw9 (pdf)</a>
<a href="hw9.tex">hw9 (tex)</a>
<a href="bi-dir-lstm.png">fig (lstm)</a>
</td>
</tr>
<tr>
<td>11</td><td>04/08/2025</td>
<td>Transformer and Large Language Model</td><td><a href="L10-llm.pdf">[lecture] 
<a href="t10.pptx">[tutorial]</a>
</td>
<td>JM Ch 10, 11, 12 
</td>
<td>
</td>
</tr>
<tr>
<td>12</td><td>04/17/2025</td>
<td>Information Retrieval</td><td><a href="L11-ir.pdf">[lecture] 
<a href="t11.pptx">[tutorial]</a>
</td>
<td>MRS Ch 1-6
</td>
<td>
<a href="hw10.pdf">hw10 (pdf)</a>
<a href="hw10.tex">hw10 (tex)</a>
</td>
</tr>
<tr>
<td>13</td><td>04/22/2025</td>
<td>Dialogue Systems</td><td><a href="L12-dialogue.pdf">[lecture] 
<a href="t12.pptx">[tutorial]</a>
</td>
<td>JM Ch 15
</td>
<td>
</td>
</tr>
-->
</table>
<h5>Copyright (c) Kenny Q. Zhu, 2023-2025.</h5>
<br>

</body>
</html>


